{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "sacrasm_team.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Pxtri2156/CS114.K21.KHTN-/blob/master/sacrasm_team.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iNrv8WOQjqkY",
        "colab_type": "text"
      },
      "source": [
        "**Danh sách nhóm**: \n",
        "+ Phạm Xuân Trí  - 18521530 \n",
        "+ Phạm Lê Quang Nhật - 18520120"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4gbro_VFtRf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "459afa91-3268-46a6-ed36-c59dd9c21ad4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0glhxbOZF4kW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f68008c0-1d1f-4c85-c41d-956ad7800fcf"
      },
      "source": [
        "cd drive/My Drive/ML/Demo "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/ML/Demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zom5_zJPF86O",
        "colab_type": "text"
      },
      "source": [
        "#**1. Mô tả lại bài toán và cách thu thập dataset**\n",
        "Bài toán **Sacrasm Detection** đây là bài toán phát hiện có tính châm biến trong một câu văn.\n",
        "* Input: Một câu văn \n",
        "* Ouput: Câu văn được phân lớp là 1 nếu là câu châm biến, ngược lại nó được phân lớp là 0.\n",
        "\n",
        "Cụ thể trong bài toán này chúng em dựa vào những headline của các bài báo điện tử trên trang **\"The Onion\"** và **\"HuffPost\"** để xây dựng mô hình dự đoán. Trang \"The Onion\" là trang chỉ chứa các headline là câu châm biến. Ngược lại với \"The Onion\", \"HuffPost\" là trang chỉ chứa các headline không phải là câu châm biến. \n",
        "\n",
        "**Cách thu thập dữ liệu**\n",
        "* Dữ liệu huấn luyện: Dữ liệu được download trên trang [kaggle](https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection) được lưu trong file.json. Mỗi dòng dữ liệu bao gồm: \n",
        "     * **article**: Link dẫn tới bài báo tương ứng\n",
        "     * **headline**: Tiêu đề của bài báo cần phân loại\n",
        "     * **is sacrasm**: Tiêu đề có phải là châm biến hay không. Nếu có mang giá trị 1, ngược lại là 0\n",
        "     \n",
        "Có tất cả **28619** dòng dữ liệu, với **x** dòng là châm biến, còn lại **y** dòng là không châm biến bộ dữ liệu này được trích ra 75% để huấn luyện.  \n",
        "* Dữ liệu kiểm thử\n",
        "    +  Lấy 25% từ bộ dữ liệu download đã nêu trên\n",
        "* Dữ liệu test\n",
        "    +  Sẽ tiến hành crawl trên 2 trang báo điện tử ở trên. Tổng cộng có 2000 headline mới. Mỗi trang 1000 headline \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FbUOJKAUGJxD",
        "colab_type": "text"
      },
      "source": [
        "#**2.Thu thập dữ liệu mới**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aoiWqFfGKTi",
        "colab_type": "text"
      },
      "source": [
        "#### **Dữ liệu mới từ Onion**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkNCqBNvGYw_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "'''  \n",
        " brief_ids và photo_ids là các id tưng ứng của  dẫn tới link các bài báo khác nhau\n",
        "\n",
        "'''\n",
        "brief_ids = [1592311200653, 1591726080182, 1591127280478, 1590584520209, \n",
        "             1589894280339, 1589294340828, 1588711020164, 1588080060229, \n",
        "             1587147720532, 1586546460312, 1586184540217, 1585581600531,\n",
        "             1582920840434, 1582639200695, 1582128720515, 1581532200479,\n",
        "             1581099360048, 1580744340055, 1580142900840, 1579637820343,\n",
        "             1579096620327, 1578410280620, 1576700820848, 1576184280994,\n",
        "             1575574260415, 1575036000486, 1574361720213, 1573762560848,\n",
        "             1573477200438, 1572900480129, 1572348600499, 1571938620032,\n",
        "             1571419440061]\n",
        "\n",
        "photo_ids = [1590159060816, 1588708260098, 1587653040878, 1585925400900,\n",
        "             1584127800188, 1582815000473, 1582061760395, 1580835900882,\n",
        "             1579528800910, 1576610760393, 1574702400578, 1573153500106,\n",
        "             1571849700244, 1570194000584, 1569247200599, 1567182180912,\n",
        "             1565892720386, 1564614900603, 1563235200067, 1560963960321,\n",
        "             1559133180370, 1557413700296, 1556108520577, 1554495180638,\n",
        "             1552834800968, 1551123540512, 1550160960071, 1548972300054,\n",
        "             1547739780965, 1544713860139, 1543513440446, 1541701980758,\n",
        "             1539720900721]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-2ugzzMGZxD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def Onion_crawler(tag, ids, num_articles, label=1):\n",
        "    count = 0\n",
        "    for id in ids:\n",
        "      source = requests.get(\"https://www.theonion.com/c/{}?startTime={}\".format(tag,id)).text\n",
        "      soup = BeautifulSoup(source, 'lxml')\n",
        "      for article in soup.find_all('article'):\n",
        "          headline = article.h2.text\n",
        "          csv_writer.writerow([label, headline])\n",
        "          count += 1\n",
        "          if count == num_articles:\n",
        "              print(f\"Crawled {count} headlines from {tag} tag\")\n",
        "              return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5QM8I7xUGeET",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d579c9e-3b96-4415-b220-1a425b7b5628"
      },
      "source": [
        "csv_file = open('onion_headlines.csv', 'w')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['is_sarcastic', 'headline'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNsW8-ODGhZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "57e91f08-dab5-4460-9ce4-6bc73fb59d6a"
      },
      "source": [
        "Onion_crawler(\"news-in-brief\", brief_ids, num_articles=644, label=1)\n",
        "Onion_crawler(\"news-in-photos\", photo_ids, num_articles=643, label=1)\n",
        "csv_file.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Crawled 644 headlines from news-in-brief tag\n",
            "Crawled 643 headlines from news-in-photos tag\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCu6AE7AGmbm",
        "colab_type": "text"
      },
      "source": [
        "#### **Dữ liệu mới từ Huffpost**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9oFEv2UGsF9",
        "colab_type": "text"
      },
      "source": [
        "Ta lấy data từ API của HuffPost.\n",
        "\n",
        "- Đầu tiên gửi request lấy [500 bài báo đầu tiên](https://www.huffpost.com/api/department/news/cards?page=1&limit=500) từ API. Tại đây ta copy toàn bộ file json và lưu vào file huffpost_part1.json.\n",
        "-  Tiếp theo ta gửi request lấy [500 bài báo tiếp theo](https://www.huffpost.com/api/department/news/cards?page=2&limit=500) từ API. Tuy nhiên lần này API chỉ trả về 194 bài báo. HuffPost API chỉ cho ta request 694 bài báo gần đây. Ta copy file json và lưu vào file huffpost_part2.json.\n",
        "    chen hinh here\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqcLVXzLGvIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jir30mnJGwoJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('part1.json') as f:\n",
        "    part1 = json.load(f)\n",
        "\n",
        "with open('part2.json') as f:\n",
        "    part2 = json.load(f)\n",
        "\n",
        "csv_file = open('huffpost_headlines.csv', 'w')\n",
        "csv_writer = csv.writer(csv_file)\n",
        "csv_writer.writerow(['is_sarcastic', 'headline'])\n",
        "\n",
        "for article in part1[\"cards\"]:\n",
        "    headline = article[\"headlines\"][0][\"text\"]\n",
        "    csv_writer.writerow([0, headline])\n",
        "    \n",
        "for article in part2[\"cards\"]:\n",
        "    headline = article[\"headlines\"][0][\"text\"]\n",
        "    csv_writer.writerow([0, headline])\n",
        "\n",
        "csv_file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4z6GbAkG09y",
        "colab_type": "text"
      },
      "source": [
        "#**3. Mô tả cách xử lý dữ liệu, feature engineering trên dataset đã cho.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "392cT_z2G3dc",
        "colab_type": "text"
      },
      "source": [
        "####  Cài đặt các thư viện cần thiết"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhd2h8FSGyzb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import re,string"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKQM8WGwHwDl",
        "colab_type": "text"
      },
      "source": [
        "#### Tải dữ liệu train và phân chia thành 2 phần: tập validation và tập train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K24XXEZaHwmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train = pd.read_json(\"SarcasmDatasetv2.json\",lines=True)\n",
        "X = data_train['headline']\n",
        "Y = data_train['is_sarcastic']\n",
        "\n",
        "#split validation:25%, train:75%\n",
        "trainX,valX,trainY,valY = train_test_split(X,Y,test_size=0.25,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD31XdqyI8rb",
        "colab_type": "text"
      },
      "source": [
        "#### Tải dữ liệu test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-V0R-M9I_Xd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onion = pd.read_csv(\"onion_headlines.csv\")\n",
        "onion_X = onion['headline']\n",
        "onion_Y = onion['is_sarcastic']\n",
        "\n",
        "huffpost = pd.read_csv(\"huffpost_headlines.csv\")\n",
        "huffpost_X = huffpost['headline']\n",
        "huffpost_Y = huffpost['is_sarcastic']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nt94WfeMJC__",
        "colab_type": "text"
      },
      "source": [
        "#### Tiền xử lí dữ liệu \n",
        "- Các headline sẽ được chuyển về lowercase, loại bỏ các ký tự đặc biệt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-cPdwX-JKwP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub('\\[.*?\\]', '', text)\n",
        "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
        "    text = re.sub('\\w*\\d\\w*', '', text)\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DN2WCH8JNi4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = trainX.apply(clean_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RF-xO55JP6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valX = valX.apply(clean_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLhp2aNoJSOV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "onion_X = onion_X.apply(clean_text)\n",
        "huffpost_X = huffpost_X.apply(clean_text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n4kBzkbJWOS",
        "colab_type": "text"
      },
      "source": [
        "#### Feature engineering cho bộ data train,test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROe7ozgiJjZo",
        "colab_type": "text"
      },
      "source": [
        "- Sử dụng TfidfVectorizer để trích xuất đặc trưng.\n",
        "- Khai báo TfidfVectorizer để biểu diễn dữ liệu train dưới dạng vector và tạo một từ điển từ dữ liệu train\n",
        "- Sử dụng lại từ điển của dữ liệu train để biểu diễn dữ liệu validation, test dưới dạng vector"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQ0prjaIJVeY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c15e4d4-9a11-4e25-d5ba-32d46fe72b86"
      },
      "source": [
        "# khởi tạo TfidfVectorizer\n",
        "tf = TfidfVectorizer(ngram_range=(1,2), max_features=40000, min_df=2)\n",
        "\n",
        "# chuyển words sang vetor\n",
        "trainX = tf.fit_transform(trainX.values).toarray()\n",
        "trainVocab = tf.vocabulary_ \n",
        "tf = TfidfVectorizer(vocabulary=trainVocab)\n",
        "\n",
        "valX = tf.fit_transform(valX.values).toarray()\n",
        "\n",
        "onion_X = tf.fit_transform(onion_X.values).toarray()\n",
        "huffpost_X = tf.fit_transform(huffpost_X.values).toarray()\n",
        "testX = np.concatenate((onion_X,huffpost_X),axis=0)\n",
        "testY = np.concatenate((onion_Y,huffpost_Y),axis=0)\n",
        "print(\"[INFO] Used TfidfVectorizer ... \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] Used TfidfVectorizer ... \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5bVtXQvJb8W",
        "colab_type": "text"
      },
      "source": [
        "#**4. Mô tả quá trình chọn model, học và fine tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ys3ywhYJt8V",
        "colab_type": "text"
      },
      "source": [
        "- Sử dụng các thuật toán như Suport vector classifications, Naive Bayes, Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-IcP_EUJ2Ad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = LogisticRegression()\n",
        "model2 = MultinomialNB()\n",
        "model3 = LinearSVC()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXM2n2B5J6q9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 538
        },
        "outputId": "5490b286-a96f-499c-efa2-bbac1131184d"
      },
      "source": [
        "for i in range(3):\n",
        "    \n",
        "    if i == 0:\n",
        "\n",
        "        print(\"   [INFO] evaluating Logistic Regression...\")\n",
        "\n",
        "        # train and evaluating \n",
        "        model1.fit(trainX, trainY)\n",
        "        predict_val_1 = model1.predict(valX)\n",
        "        predict_test_1 = model1.predict(testX)\n",
        "\n",
        "        print(classification_report(valY,predict_val_1))\n",
        "\n",
        "    if i == 1:\n",
        "        \n",
        "        print(\"   [INFO] evaluating Naive Bayes...\")\n",
        "\n",
        "        # train and evaluating \n",
        "        model2.fit(trainX, trainY)\n",
        "        predict_val_2 = model2.predict(valX)\n",
        "        predict_test_2 = model2.predict(testX)\n",
        "\n",
        "        print(classification_report(valY,predict_val_2))\n",
        "\n",
        "    if i == 2:\n",
        "\n",
        "        print(\"   [INFO] evaluating SVM...\")\n",
        "\n",
        "        model3.fit(trainX, trainY)\n",
        "        predict_val_3 = model3.predict(valX)\n",
        "        predict_test_3 = model3.predict(testX)\n",
        "\n",
        "        print(classification_report(valY,predict_val_3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   [INFO] evaluating Logistic Regression...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.81      0.83      3730\n",
            "           1       0.80      0.84      0.82      3425\n",
            "\n",
            "    accuracy                           0.82      7155\n",
            "   macro avg       0.82      0.83      0.82      7155\n",
            "weighted avg       0.83      0.82      0.82      7155\n",
            "\n",
            "   [INFO] evaluating Naive Bayes...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85      3730\n",
            "           1       0.86      0.79      0.82      3425\n",
            "\n",
            "    accuracy                           0.83      7155\n",
            "   macro avg       0.84      0.83      0.83      7155\n",
            "weighted avg       0.84      0.83      0.83      7155\n",
            "\n",
            "   [INFO] evaluating SVM...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.83      0.83      3730\n",
            "           1       0.82      0.82      0.82      3425\n",
            "\n",
            "    accuracy                           0.83      7155\n",
            "   macro avg       0.83      0.83      0.83      7155\n",
            "weighted avg       0.83      0.83      0.83      7155\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmSAa0ThKqRb",
        "colab_type": "text"
      },
      "source": [
        "#**5. Mô tả cách dùng model đã train để viết một đoạn chương trình ngắn, thực hiện sacarsm detection cho một headline bất kỳ được nhập vào.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rByUDQNKtZv",
        "colab_type": "text"
      },
      "source": [
        "#### Nhập một headline bất kỳ "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixN7q-rXKyMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "450a60e3-73bd-4a89-a73b-16b07a4979a9"
      },
      "source": [
        "headline = input()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Crowds Tear Down Statues At Wisconsin Capitol, Attack State Senator\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SydbuE_KKwhW",
        "colab_type": "text"
      },
      "source": [
        "#### Tiền xử lí dữ liệu \n",
        "- Headline sẽ được chuyển về lowercase, loại bỏ các ký tự đặc biệt."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhKo-k7rK-cH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headline = [clean_text(headline)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2n77UetLLAOP",
        "colab_type": "text"
      },
      "source": [
        "#### Mã hoá headline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1pD7Or59LGqU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "headline = tf.fit_transform(headline).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RQKbvkVNLWzk",
        "colab_type": "text"
      },
      "source": [
        "#### Dự đoán"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pP2rIdCDLY_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predict = model2.predict(headline)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nX70fUWHLjBN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aeca8873-4e6d-4a7a-de0a-30c1f577800d"
      },
      "source": [
        "if predict == 1:\n",
        "    print(\"This is sarcastic_from the onion\")\n",
        "else:\n",
        "    print(\"This isn't sarcastic_from the huffpost\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This isn't sarcastic_from the huffpost\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4o9lgrUL5EN",
        "colab_type": "text"
      },
      "source": [
        "#**6. Đối chiếu performance của model trên dataset đã cho và trên 2000 headine mới. Nhận xét về bài toán này.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3bqjqTWMNRi",
        "colab_type": "text"
      },
      "source": [
        "#### Đánh giá mô hình Naive Bayes trên dataset đã cho và trên 2000 headine mới. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6i00HkCMEPp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "d30d621c-fdb5-40c7-d008-eb6c8fd53032"
      },
      "source": [
        "print(classification_report(valY,predict_val_2))\n",
        "print(classification_report(testY,predict_test_2))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.88      0.85      3730\n",
            "           1       0.86      0.79      0.82      3425\n",
            "\n",
            "    accuracy                           0.83      7155\n",
            "   macro avg       0.84      0.83      0.83      7155\n",
            "weighted avg       0.84      0.83      0.83      7155\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.64      0.83      0.73       694\n",
            "           1       0.89      0.75      0.82      1287\n",
            "\n",
            "    accuracy                           0.78      1981\n",
            "   macro avg       0.77      0.79      0.77      1981\n",
            "weighted avg       0.81      0.78      0.79      1981\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amRMPPtJL8v6",
        "colab_type": "text"
      },
      "source": [
        "#### Nhận xét"
      ]
    }
  ]
}